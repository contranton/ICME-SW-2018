<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<title>Day 2</title>
<!-- 2018-01-11 Thu 00:10 -->
<meta  http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta  name="generator" content="Org-mode" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center; }
  .todo   { font-family: monospace; color: red; }
  .done   { color: green; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  pre.src-sh:before    { content: 'sh'; }
  pre.src-bash:before  { content: 'sh'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-R:before     { content: 'R'; }
  pre.src-perl:before  { content: 'Perl'; }
  pre.src-java:before  { content: 'Java'; }
  pre.src-sql:before   { content: 'SQL'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.right  { text-align: center;  }
  th.left   { text-align: center;   }
  th.center { text-align: center; }
  td.right  { text-align: right;  }
  td.left   { text-align: left;   }
  td.center { text-align: center; }
  dt { font-weight: bold; }
  .footpara:nth-child(2) { display: inline; }
  .footpara { display: block; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  /*]]>*/-->
</style>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2013 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/javascript" src="http://orgmode.org/mathjax/MathJax.js"></script>
<script type="text/javascript">
<!--/*--><![CDATA[/*><!--*/
    MathJax.Hub.Config({
        // Only one of the two following lines, depending on user settings
        // First allows browser-native MathML display, second forces HTML/CSS
        //  config: ["MMLorHTML.js"], jax: ["input/TeX"],
            jax: ["input/TeX", "output/HTML-CSS"],
        extensions: ["tex2jax.js","TeX/AMSmath.js","TeX/AMSsymbols.js",
                     "TeX/noUndefined.js"],
        tex2jax: {
            inlineMath: [ ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"], ["\\begin{displaymath}","\\end{displaymath}"] ],
            skipTags: ["script","noscript","style","textarea","pre","code"],
            ignoreClass: "tex2jax_ignore",
            processEscapes: false,
            processEnvironments: true,
            preview: "TeX"
        },
        showProcessingMessages: true,
        displayAlign: "center",
        displayIndent: "2em",

        "HTML-CSS": {
             scale: 100,
             availableFonts: ["STIX","TeX"],
             preferredFont: "TeX",
             webFont: "TeX",
             imageFont: "TeX",
             showMathMenu: true,
        },
        MMLorHTML: {
             prefer: {
                 MSIE:    "MML",
                 Firefox: "MML",
                 Opera:   "HTML",
                 other:   "HTML"
             }
        }
    });
/*]]>*///-->
</script>
</head>
<body>
<div id="content">
<h1 class="title">Day 2</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#sec-1">Measuring algorithm performance</a>
<ul>
<li><a href="#sec-1-1">Cross Validation</a>
<ul>
<li><a href="#sec-1-1-1">Bias vs. Variance Tradeoff</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#sec-2">Classification</a>
<ul>
<li><a href="#sec-2-1">K-Nearest Neighbor classifier</a>
<ul>
<li><a href="#sec-2-1-1">Choosing K</a></li>
<li><a href="#sec-2-1-2">Advantages</a></li>
<li><a href="#sec-2-1-3">Disadvantages</a></li>
</ul>
</li>
<li><a href="#sec-2-2">Regression</a>
<ul>
<li><a href="#sec-2-2-1">Linear Regression</a></li>
<li><a href="#sec-2-2-2">Logistic Regression</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#sec-3">Cross-Validation and Regularization</a>
<ul>
<li><a href="#sec-3-1">Cross-Validation</a>
<ul>
<li><a href="#sec-3-1-1">XKCD example with the jelly beans and medical research</a></li>
<li><a href="#sec-3-1-2"><span class="todo TODO">TODO</span> Loss Functions</a></li>
<li><a href="#sec-3-1-3"><span class="todo TODO">TODO</span> Classification Loss Functions</a></li>
<li><a href="#sec-3-1-4"><span class="todo TODO">TODO</span> Supervised Learning Theory</a></li>
<li><a href="#sec-3-1-5">K-fold Cross Validation</a></li>
<li><a href="#sec-3-1-6">Bias-Variance tradeoff</a></li>
<li><a href="#sec-3-1-7">Learning Curves</a></li>
<li><a href="#sec-3-1-8">Common problems!!</a></li>
<li><a href="#sec-3-1-9"><span class="todo TODO">TODO</span> Importance of the validation set</a></li>
<li><a href="#sec-3-1-10">Training data issues</a></li>
</ul>
</li>
<li><a href="#sec-3-2">Regularization</a>
<ul>
<li><a href="#sec-3-2-1">Problems with models</a></li>
<li><a href="#sec-3-2-2">Ridge Regression</a></li>
<li><a href="#sec-3-2-3">Lasso</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<div id="outline-container-sec-1" class="outline-2">
<h2 id="sec-1">Measuring algorithm performance</h2>
<div class="outline-text-2" id="text-1">
<p>
Loss functions quantify cost of errors. E.g: Mean Squared Error (MSE) = \(\frac{1}{N}\sum\left(y_i-f(x_i)\right)^2\)
</p>

<p>
Keep in mind that we don't want to minimize the error on the data we have (that leads to overfitting. Rather, we want to minimize the error on <i>new data</i>, such that we build a model that <i>generalizes</i>, rather than just fit the trends.
</p>

<p>
In the end, we want to minimize the <i>expected loss</i> on future data.
</p>

<p>
Training error and Test error behave differently. As our model flexibility increases, the training error always decreases, but past a certain point the test error will actually begin to increase!
</p>

<p>
When the number of degrees of freedom approaches the size of the data we get into dangerous overfitting territory. Complex models like deep neural networks involve millions of parameters, though at the same time they require far larger datasets to train.
</p>
</div>
<div id="outline-container-sec-1-1" class="outline-3">
<h3 id="sec-1-1">Cross Validation</h3>
<div class="outline-text-3" id="text-1-1">
<p>
Divide the data into three subsets:
</p>
<ul class="org-ul">
<li>Training data: Subset used to learn the model
</li>
<li>Validation data: Subset used to estimate error for tuning or model selection
</li>
<li>Test data: Subset used to check model performance. This has not been previously been used on the model.
</li>
</ul>
</div>
<div id="outline-container-sec-1-1-1" class="outline-4">
<h4 id="sec-1-1-1">Bias vs. Variance Tradeoff</h4>
<div class="outline-text-4" id="text-1-1-1">
<p>
The expectation of the error for the given estimator (i.e., model) is given by
</p>

<p>
\(\text{Variance(}f\hat\text{)} + \text{Bias(}f\hat\text{)}^2 + \text{Variance(}\varepsilon\text{)}\)
</p>

<p>
The bias represents the ability of the model to represent the actual trend. For example, trying to linearly fit a nonlinear model is biased towards the linear fit wheras a slightly more complex model would fit the data better.
</p>

<p>
Variance, on the other hand, quantifies how much the estimation varies with different datasets.
</p>

<p>
As we increase the DOFs, bias is reduced, but at the same time variance is increased.
</p>

<p>
Ideally, low bias <i>and</i> low variance imply a low test error.
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-sec-2" class="outline-2">
<h2 id="sec-2">Classification</h2>
<div class="outline-text-2" id="text-2">
</div><div id="outline-container-sec-2-1" class="outline-3">
<h3 id="sec-2-1">K-Nearest Neighbor classifier</h3>
<div class="outline-text-3" id="text-2-1">
<p>
Basic idea: classify observations based on nearby labels.
</p>

<p>
The predicted class for a sample X is the most common class among its K nearest neighbors from the training set.
</p>

<p>
The probability of belonging to some class is quite easily \(\frac{\#\text{(class among neighbors)}}{K}\).
</p>

<p>
Decision boundaries are a useful way of visualizing the regions of classification as well as noting the complexity of some fit.
</p>

<p>
This is a <i>non-parametric</i> model, as we're not fitting an equation with fixed parameters.
</p>

<p>
Useful for interpolating data!
</p>
</div>
<div id="outline-container-sec-2-1-1" class="outline-4">
<h4 id="sec-2-1-1">Choosing K</h4>
<div class="outline-text-4" id="text-2-1-1">
<p>
With small K, we overfit and the decision boundary is very rough and jittery. However, with a large K the data might not be abundant enough to capture <i>any</i> trends.
</p>

<p>
Again, by minimizing the expected error we can choose the optimal K.
</p>
</div>
</div>
<div id="outline-container-sec-2-1-2" class="outline-4">
<h4 id="sec-2-1-2">Advantages</h4>
<div class="outline-text-4" id="text-2-1-2">
<ul class="org-ul">
<li>Simple to implement
</li>
<li>Few tuning parameters (K, distance metric)
</li>
<li>Flexible, doesn't impose linear separability
</li>
</ul>
</div>
</div>
<div id="outline-container-sec-2-1-3" class="outline-4">
<h4 id="sec-2-1-3">Disadvantages</h4>
<div class="outline-text-4" id="text-2-1-3">
<ul class="org-ul">
<li>Computationally expensive
</li>
<li>Sensitive to imbalanced datasets (larger classes smother the smaller ones)
</li>
<li>Sensitive to irrelevant inputs
</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-sec-2-2" class="outline-3">
<h3 id="sec-2-2">Regression</h3>
<div class="outline-text-3" id="text-2-2">
</div><div id="outline-container-sec-2-2-1" class="outline-4">
<h4 id="sec-2-2-1">Linear Regression</h4>
<div class="outline-text-4" id="text-2-2-1">
<p>
It's a simple supervised learning method! Its advantage is <i>highly interpretable</i> as the slope parameters easily quantify the impact of individual variables.
</p>
</div>
<ul class="org-ul"><li><a id="sec-2-2-1-1" name="sec-2-2-1-1"></a>Simple Linear Regression<br  /><div class="outline-text-5" id="text-2-2-1-1">
<p>
Parametric model given by \(Y=\beta_0 + \beta_1 X + \varepsilon\).
</p>

<p>
We estimate $\hat&beta;<sub>0</sub> and $\hat&beta;<sub>1</sub> using training data to find a good fit, and for this we usually use the Mean Squared Error.
</p>

<p>
SLR in particular has a closed-form solution for the parameters that gives the best least-squares fit.
</p>
</div>
</li>
<li><a id="sec-2-2-1-2" name="sec-2-2-1-2"></a>Multiple Linear Regression<br  /><div class="outline-text-5" id="text-2-2-1-2">
<p>
We use more than one predictor (X) variable on the form Y=&beta;<sub>0</sub>+&beta;<sub>1</sub> X+&beta;<sub>2</sub> X<sub>2</sub>+&#x2026;
</p>

<p>
Using the magic of linear algebra, we may define X and &beta; vectors to set up the optimization problem \hat&beta; = argmin<sub>&beta;</sub> ||Y - X<sup>T</sup>&beta; ||<sup>2</sup>. This also has a closed-form solution (found through the <i>normal equations</i>) given by \(\beta = \left(X^TX\right)^{-1}X^TY\)
</p>
</div>
</li>

<li><a id="sec-2-2-1-3" name="sec-2-2-1-3"></a>Variations on Linear Regression<br  /><ul class="org-ul"><li><a id="sec-2-2-1-3-1" name="sec-2-2-1-3-1"></a>Weighted Linear Regression<br  /><div class="outline-text-6" id="text-2-2-1-3-1">
<p>
Not all data is created equal &#x2013; if we know a particular subset of data is less reliable, i.e. more noisy, we reduce its impact on the model through weighting.
</p>

<p>
Using a diagonal matrix \(W\) with elements $w<sub>i</sub> = \frac{1}{\sigma_i^2} where each &sigma;<sub>i</sub> may be esoteric or properly measured. With this, the problem becomes
</p>
</div>
</li>
<li><a id="sec-2-2-1-3-2" name="sec-2-2-1-3-2"></a>Locally weighted linear regression<br  /><div class="outline-text-6" id="text-2-2-1-3-2">
<p>
We pressume an <i>a priori</i> interest in some particular region of data. For some observation, we apply a gaussian weighing surrounding the point of interest to produce a sort of tangent line.
</p>

<p>
A new linear fit must be produced for <i>every</i> desired observation, and in the end this produces a piece-wise linear approximation to the trend curve.
</p>
</div>
</li></ul>
</li></ul>
</div>
<div id="outline-container-sec-2-2-2" class="outline-4">
<h4 id="sec-2-2-2">Logistic Regression</h4>
<div class="outline-text-4" id="text-2-2-2">
</div><ul class="org-ul"><li><a id="sec-2-2-2-1" name="sec-2-2-2-1"></a>Qualitative inputs<br  /><div class="outline-text-5" id="text-2-2-2-1">
<p>
Class predictors like KNN are based on purely categorical data. However, it's possible to classify <i>using regression</i> by regressing probabilities of belonging to different classes.
</p>

<p>
When input data is qualitative, (e.g. "female", "male", "blue eyes", "brown eyes") it's easy to use binary variables that quantify this. However, it's dangerous to apply a linear regression with categories assigned to different numbers (i.e. symptoms: headache:1, seizure:2, stroke:3) to any categories as this introduces unnatural orderings that bias the fit.
</p>

<p>
The best way of dealing with categorical data is using <i>binary variables</i>. Either 1 or 0 whether the category is true or not.
</p>
</div>
</li>
<li><a id="sec-2-2-2-2" name="sec-2-2-2-2"></a>Description<br  /><div class="outline-text-5" id="text-2-2-2-2">
<p>
\(Y\) takes on two values: 0 or 1, and we estimate it with probabilities in the interval \([0-1]\). 
</p>

<p>
We use the sigmoid/logistic function \(\sigma(z)=\frac{1}{1+e^{-z}}\) that lies in the desired interval. By making \(z\) the linear regressor (Xs aren't forced to be binary), we can "squash" the data to perform categorical fitting.
</p>

<p>
By choosing the sub-space where \(\mathbb{P}=p\) we can define the decision boundary for the classification, so instead of fitting a line, we're fitting a sort of <i>step</i> function.
</p>
</div>
</li>
<li><a id="sec-2-2-2-3" name="sec-2-2-2-3"></a>Advantages<br  /><div class="outline-text-5" id="text-2-2-2-3">
<ul class="org-ul">
<li>Extension of Linear Regression
</li>
<li>Interpretability &#x2013; log-odds are linear
</li>
<li>No tuning of hyperparameters
</li>
</ul>
</div>
</li>
<li><a id="sec-2-2-2-4" name="sec-2-2-2-4"></a>Disadvantages<br  /><div class="outline-text-5" id="text-2-2-2-4">
<ul class="org-ul">
<li>Can't model complex decision boundaries
</li>
<li>May overfit in training data, though it can be mitigated with Regularization in the MLE method
</li>
<li>Problem <b>must</b> be formulated as binary classification
</li>
</ul>
</div>
</li></ul>
</div>
</div>
</div>

<div id="outline-container-sec-3" class="outline-2">
<h2 id="sec-3">Cross-Validation and Regularization</h2>
<div class="outline-text-2" id="text-3">
</div><div id="outline-container-sec-3-1" class="outline-3">
<h3 id="sec-3-1">Cross-Validation</h3>
<div class="outline-text-3" id="text-3-1">
</div><div id="outline-container-sec-3-1-1" class="outline-4">
<h4 id="sec-3-1-1">XKCD example with the jelly beans and medical research</h4>
<div class="outline-text-4" id="text-3-1-1">
<p>
<a href="https://xkcd.com/882/">Statistical significance</a> has no meaning if we don't properly manage our p-values to account for the fact that we're bombarding the data with the same models. If we get results, it's probably because we arrived at the \(p%\) of times that we get it from pure chance!
</p>
</div>
</div>
<div id="outline-container-sec-3-1-2" class="outline-4">
<h4 id="sec-3-1-2"><span class="todo TODO">TODO</span> Loss Functions</h4>
<div class="outline-text-4" id="text-3-1-2">
<p>
In linear regression, why do we use the squared error instead of just the absolute error? Usually it's because it gives us a closed form solution.
</p>
</div>

<ul class="org-ul"><li><a id="sec-3-1-2-1" name="sec-3-1-2-1"></a>Squared Error<br  /><div class="outline-text-5" id="text-3-1-2-1">
<p>
\(\sum_j\left(Y-f(X)\right)^2\)
</p>

<p>
This is affected much more by outliers, as they make the square error far larger than the simple distance. This error function leads to the mean, which presents high sensitivity.
</p>
</div>
</li>
<li><a id="sec-3-1-2-2" name="sec-3-1-2-2"></a>Absolute Error<br  /><div class="outline-text-5" id="text-3-1-2-2">
<p>
\(\sum_j\left|Y-f(X)\right|\)
</p>

<p>
Since there's no further penalization of far-away terms, this loss function is less sensitive to outliers. This gives rise to the median, a far more stable central measure.
</p>
</div>
</li></ul>
</div>

<div id="outline-container-sec-3-1-3" class="outline-4">
<h4 id="sec-3-1-3"><span class="todo TODO">TODO</span> Classification Loss Functions</h4>
<div class="outline-text-4" id="text-3-1-3">
<p>
Indicator error (nuumber of times "I screwed up", i.e. classifying spam(1) as not-spam(0)).
</p>


<p>
"Flip" what we're saying: If we get something wrong 80% of the time, just flip the classification!
</p>
</div>

<ul class="org-ul"><li><a id="sec-3-1-3-1" name="sec-3-1-3-1"></a><span class="todo TODO">TODO</span> Misclassification<br  /><div class="outline-text-5" id="text-3-1-3-1">
<p>
Gini index of uniformity
</p>
</div>
</li></ul>
</div>

<div id="outline-container-sec-3-1-4" class="outline-4">
<h4 id="sec-3-1-4"><span class="todo TODO">TODO</span> Supervised Learning Theory</h4>
<div class="outline-text-4" id="text-3-1-4">
<p>
Given a loss function \(L(Y, \tilde f(X))\), our goal is to find \(\hat f = \argmin_{\tilde f} \mathbb{E}[L(Y, \tilde f(X))]\). That is, across the population \(X\), find the model \(\tilde f\) that minimizes the expected error.
</p>
</div>
</div>

<div id="outline-container-sec-3-1-5" class="outline-4">
<h4 id="sec-3-1-5">K-fold Cross Validation</h4>
<div class="outline-text-4" id="text-3-1-5">
<p>
We divide our data into different subsets, some of which are used for testing and some of which are used to <i>validate</i> the model. We can reshuffle the dataset and do this multiple times to get an average.
</p>

<p>
Cross-Validation Error: (tests whether a <b><i>type</i></b> of model is a good fit, rather than a particular fit). This cannot be used to replace the necessity for validation sets!
</p>

<p>
N-fold cross-validation is the best validation method &#x2013; it leaves one sample out and uses everybody else to train and later validate one the one sample. It performs this N times, meaning it's very expensive for more complex models.
</p>

<p>
Good compromises are 5-fold and 10-fold cross valdiations.
</p>

<p>
<i>Types</i> of models can be understood as different parameters for a single model, e.g. 2 neighbors for KNN vs 3 neighbors, etc.
</p>
</div>
</div>

<div id="outline-container-sec-3-1-6" class="outline-4">
<h4 id="sec-3-1-6">Bias-Variance tradeoff</h4>
<div class="outline-text-4" id="text-3-1-6">
<p>
See <a href="#sec-1-1-1">Previous Heading</a>.
</p>
</div>
</div>

<div id="outline-container-sec-3-1-7" class="outline-4">
<h4 id="sec-3-1-7">Learning Curves</h4>
<div class="outline-text-4" id="text-3-1-7">
<p>
How do we answer the question: do we need a better model or do we need more data?
</p>

<p>
Compare the training error and Cross-validation error as the data size changes <i>with the same model</i>. As we increase the data size, the same fit isn't as able to fit newer data so the <i>training error increases</i> as the cross-validation error decreases and eventually bottoms out. These errors never actually cross, but when the curves flatten out it's time to get a better model.
</p>

<p>
In summary, big gap implies we need more data, small gaps imply it's time to improve the model.
</p>
</div>
</div>

<div id="outline-container-sec-3-1-8" class="outline-4">
<h4 id="sec-3-1-8">Common problems!!</h4>
<div class="outline-text-4" id="text-3-1-8">
<p>
The test sets must <i>never be used until testing</i>. We can't use them to extract information that will affect how we develop the models.
</p>

<p>
Be careful with using too many different models on the same test set. Eventually, a model will <i>by chance</i> fit the model well.
</p>
</div>
</div>

<div id="outline-container-sec-3-1-9" class="outline-4">
<h4 id="sec-3-1-9"><span class="todo TODO">TODO</span> Importance of the validation set</h4>
<div class="outline-text-4" id="text-3-1-9">
<p>
Only, and only when we've exhausted the model space and found a model that might
</p>
</div>
</div>

<div id="outline-container-sec-3-1-10" class="outline-4">
<h4 id="sec-3-1-10">Training data issues</h4>
<div class="outline-text-4" id="text-3-1-10">
</div><ul class="org-ul"><li><a id="sec-3-1-10-1" name="sec-3-1-10-1"></a>Data is biased!<br  /><div class="outline-text-5" id="text-3-1-10-1">
<p>
As an example, historical text incorporates sexism (4 times more male references to female ones, as well as other biases in content) that gets incorporated into automated systems unnoticed.
</p>

<blockquote>
<p>
Machine Learning is like money laundering for bias. It's a clean, mathematical apparatus that gives the status quo the aura of logical invenitability
&#x2013;Maciej Ceglowski
</p>
</blockquote>
</div>
</li></ul>
</div>
</div>

<div id="outline-container-sec-3-2" class="outline-3">
<h3 id="sec-3-2">Regularization</h3>
<div class="outline-text-3" id="text-3-2">
<p>
"Too many cooks spoil the soup"
</p>

<p>
Many models for regression involve many variables or so-called "proprietary" variables &#x2013; functions of the other variables.
</p>
</div>

<div id="outline-container-sec-3-2-1" class="outline-4">
<h4 id="sec-3-2-1">Problems with models</h4>
<div class="outline-text-4" id="text-3-2-1">
</div><ul class="org-ul"><li><a id="sec-3-2-1-1" name="sec-3-2-1-1"></a>More variables than samples<br  /><div class="outline-text-5" id="text-3-2-1-1">
<p>
Having too few samples for very high-dimensional models allow us to fit an infinitude of spaces. For example fitting two samples to a three dimensional model lets us fit infinitely many planes that pass through the line connecting the samples.
</p>
</div>
</li>
<li><a id="sec-3-2-1-2" name="sec-3-2-1-2"></a>Multiple-Colinearity<br  /><div class="outline-text-5" id="text-3-2-1-2">
<p>
What can go wrong when we have a few variables that are highly correlated between each other but not with the variable we're trying to predict? When performing a fit, these variables won't affect the predictor and might happen to cancel out mutually &#x2013; because of this, their weights might become disproportionally large, making it seem like these variables are actually very important when in fact they're not!
</p>
</div>
</li></ul>
</div>


<div id="outline-container-sec-3-2-2" class="outline-4">
<h4 id="sec-3-2-2">Ridge Regression</h4>
<div class="outline-text-4" id="text-3-2-2">
<p>
Incorporate a 'penalized error' \(\lambda \left(\sum\beta_i^2\right)\). 
</p>

<p>
As &lambda; increases, the <i>bias</i> increases as we end up simplifying the model (&beta;<sub>i</sub> tend to zero), and the variance decreases as we always reach the same estimations.
</p>
</div>
</div>

<div id="outline-container-sec-3-2-3" class="outline-4">
<h4 id="sec-3-2-3">Lasso</h4>
<div class="outline-text-4" id="text-3-2-3">
<p>
How do we choose which variables can be tuned to <i>exactly</i> zero?
</p>

<p>
"Least Absolute Shrinkage and Selection Operator"
</p>

<p>
Rather than squaring the betas, we use their absolute value. Thus, the penalty is \(\lambda\left(\sum|\beta_i|\right)\)
</p>

<p>
This becomes an L1 problem rather than an L2 problem used in Ridge Regression. It doesn't find smooth values very well but it approaches zero very reliably. Because of this, our data is able to become sparse much more reliably.
</p>
</div>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="date">Created: 2018-01-11 Thu 00:10</p>
<p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 25.1.1 (<a href="http://orgmode.org">Org</a> mode 8.2.10)</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
